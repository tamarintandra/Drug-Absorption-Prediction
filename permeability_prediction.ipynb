{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyTDC\n",
    "!pip install rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tdc.single_pred import ADME\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ADME(name = 'PAMPA_NCATS')\n",
    "split = data.get_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = split['train']\n",
    "valid_df = split['valid']\n",
    "test_df = split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_descriptors(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    descriptors = {}\n",
    "    for descriptor_name, function in Descriptors.descList:\n",
    "        descriptors[descriptor_name] = function(mol)\n",
    "    return descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate descriptors for train, valid, and test sets\n",
    "train_df['Descriptors'] = train_df['Drug'].apply(calculate_descriptors)\n",
    "valid_df['Descriptors'] = valid_df['Drug'].apply(calculate_descriptors)\n",
    "test_df['Descriptors'] = test_df['Drug'].apply(calculate_descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and labels\n",
    "X_train = pd.DataFrame(train_df['Descriptors'].tolist())\n",
    "y_train = train_df['Y']\n",
    "\n",
    "X_valid = pd.DataFrame(valid_df['Descriptors'].tolist())\n",
    "y_valid = valid_df['Y']\n",
    "\n",
    "X_test = pd.DataFrame(test_df['Descriptors'].tolist())\n",
    "y_test = test_df['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Impute missing values with mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_valid_imputed = imputer.fit_transform(X_valid)\n",
    "\n",
    "# Convert X_valid_imputed to a DataFrame\n",
    "X_valid_imputed_df = pd.DataFrame(X_valid_imputed, columns=X_valid.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate training and validation datasets\n",
    "X_combined = pd.concat([X_train, X_valid_imputed_df], axis=0)\n",
    "y_combined = pd.concat([y_train, y_valid], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, cohen_kappa_score, accuracy_score\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=200)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(rf_classifier, X_combined, y_combined, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-Validation Scores:\", cv_scores)\n",
    "print(\"Mean Accuracy:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "rf_classifier.fit(X_combined, y_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    auc_roc = roc_auc_score(y, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    balanced_accuracy = (sensitivity + specificity) / 2\n",
    "    kappa = cohen_kappa_score(y, y_pred)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "\n",
    "    return auc_roc, sensitivity, specificity, balanced_accuracy, kappa, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "auc_roc_test, sensitivity_test, specificity_test, balanced_accuracy_test, kappa_test, accuracy = evaluate_model(rf_classifier, X_test, y_test)\n",
    "print(\"\\nTest Performance:\")\n",
    "print(\"AUC-ROC:\", auc_roc_test)\n",
    "print(\"Sensitivity:\", sensitivity_test)\n",
    "print(\"Specificity:\", specificity_test)\n",
    "print(\"Balanced Accuracy:\", balanced_accuracy_test)\n",
    "print(\"Cohen's Kappa:\", kappa_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
